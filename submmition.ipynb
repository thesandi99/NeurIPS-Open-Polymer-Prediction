{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9698119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T16:13:13.346317Z",
     "iopub.status.busy": "2025-09-12T16:13:13.345794Z",
     "iopub.status.idle": "2025-09-12T16:13:26.482278Z",
     "shell.execute_reply": "2025-09-12T16:13:26.481061Z"
    },
    "papermill": {
     "duration": 13.141879,
     "end_time": "2025-09-12T16:13:26.484085",
     "exception": false,
     "start_time": "2025-09-12T16:13:13.342206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (1.26.4)\r\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit==2025.3.3) (11.2.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rdkit==2025.3.3) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rdkit==2025.3.3) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rdkit==2025.3.3) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rdkit==2025.3.3) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rdkit==2025.3.3) (2024.2.0)\r\n",
      "Installing collected packages: rdkit\r\n",
      "Successfully installed rdkit-2025.3.3\r\n",
      "Looking in links: file:///kaggle/input/mordred-1-2-0-py3-none-any/\r\n",
      "Processing /kaggle/input/mordred-1-2-0-py3-none-any/mordred-1.2.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: six==1.* in /usr/local/lib/python3.11/dist-packages (from mordred) (1.17.0)\r\n",
      "Requirement already satisfied: numpy==1.* in /usr/local/lib/python3.11/dist-packages (from mordred) (1.26.4)\r\n",
      "Processing /kaggle/input/mordred-1-2-0-py3-none-any/networkx-2.8.8-py3-none-any.whl (from mordred)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy==1.*->mordred) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy==1.*->mordred) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy==1.*->mordred) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy==1.*->mordred) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy==1.*->mordred) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy==1.*->mordred) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.*->mordred) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy==1.*->mordred) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy==1.*->mordred) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy==1.*->mordred) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy==1.*->mordred) (2024.2.0)\r\n",
      "Installing collected packages: networkx, mordred\r\n",
      "  Attempting uninstall: networkx\r\n",
      "    Found existing installation: networkx 3.5\r\n",
      "    Uninstalling networkx-3.5:\r\n",
      "      Successfully uninstalled networkx-3.5\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "scikit-image 0.25.2 requires networkx>=3.0, but you have networkx 2.8.8 which is incompatible.\r\n",
      "nx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 2.8.8 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed mordred-1.2.0 networkx-2.8.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/rdkit-2025-3-3-cp311/rdkit-2025.3.3-cp311-cp311-manylinux_2_28_x86_64.whl\n",
    "!pip install mordred --no-index --find-links=file:///kaggle/input/mordred-1-2-0-py3-none-any/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c559067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-12T16:13:26.491895Z",
     "iopub.status.busy": "2025-09-12T16:13:26.491332Z",
     "iopub.status.idle": "2025-09-12T16:21:28.913203Z",
     "shell.execute_reply": "2025-09-12T16:21:28.912191Z"
    },
    "papermill": {
     "duration": 482.427851,
     "end_time": "2025-09-12T16:21:28.914951",
     "exception": false,
     "start_time": "2025-09-12T16:13:26.487100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration and seeding function defined.\n",
      "Loading data...\n",
      "Generating Mordred descriptors for 3 molecules (test)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 525 descriptors for test.\n",
      "✅ Features generated. Train shape: (7973, 532), Test shape: (3, 527)\n",
      "✅ Feature selection and transformation functions defined.\n",
      "\n",
      "=== Initiating Training ===\n",
      "\n",
      "[TG]\n",
      "\n",
      "--- Training with seed: 42 ---\n",
      "  Target: Tg | Model: LightGBM\n",
      "    Fold 1/5\n",
      "      Fold 1 MAE: 42.81160\n",
      "    Fold 2/5\n",
      "      Fold 2 MAE: 45.96157\n",
      "    Fold 3/5\n",
      "      Fold 3 MAE: 50.22105\n",
      "    Fold 4/5\n",
      "      Fold 4 MAE: 48.98213\n",
      "    Fold 5/5\n",
      "      Fold 5 MAE: 49.62732\n",
      "    -> Average CV MAE for Tg: 47.52074 (+/- 2.77388)\n",
      "\n",
      "[FFV]\n",
      "\n",
      "--- Training with seed: 42 ---\n",
      "  Target: FFV | Model: LightGBM\n",
      "    Fold 1/5\n",
      "      Fold 1 MAE: 0.00698\n",
      "    Fold 2/5\n",
      "      Fold 2 MAE: 0.00696\n",
      "    Fold 3/5\n",
      "      Fold 3 MAE: 0.00700\n",
      "    Fold 4/5\n",
      "      Fold 4 MAE: 0.00616\n",
      "    Fold 5/5\n",
      "      Fold 5 MAE: 0.00695\n",
      "    -> Average CV MAE for FFV: 0.00681 (+/- 0.00033)\n",
      "\n",
      "[TC]\n",
      "\n",
      "--- Training with seed: 42 ---\n",
      "  Target: Tc | Model: LightGBM\n",
      "    Fold 1/5\n",
      "      Fold 1 MAE: 0.02516\n",
      "    Fold 2/5\n",
      "      Fold 2 MAE: 0.02796\n",
      "    Fold 3/5\n",
      "      Fold 3 MAE: 0.02236\n",
      "    Fold 4/5\n",
      "      Fold 4 MAE: 0.02916\n",
      "    Fold 5/5\n",
      "      Fold 5 MAE: 0.02589\n",
      "    -> Average CV MAE for Tc: 0.02610 (+/- 0.00236)\n",
      "\n",
      "[DENSITY]\n",
      "\n",
      "--- Training with seed: 42 ---\n",
      "  Target: Density | Model: LightGBM\n",
      "    Fold 1/5\n",
      "      Fold 1 MAE: 0.02830\n",
      "    Fold 2/5\n",
      "      Fold 2 MAE: 0.02612\n",
      "    Fold 3/5\n",
      "      Fold 3 MAE: 0.01978\n",
      "    Fold 4/5\n",
      "      Fold 4 MAE: 0.02527\n",
      "    Fold 5/5\n",
      "      Fold 5 MAE: 0.03057\n",
      "    -> Average CV MAE for Density: 0.02601 (+/- 0.00362)\n",
      "\n",
      "[RG]\n",
      "\n",
      "--- Training with seed: 42 ---\n",
      "  Target: Rg | Model: LightGBM\n",
      "    Fold 1/5\n",
      "      Fold 1 MAE: 1.39692\n",
      "    Fold 2/5\n",
      "      Fold 2 MAE: 1.36423\n",
      "    Fold 3/5\n",
      "      Fold 3 MAE: 1.52832\n",
      "    Fold 4/5\n",
      "      Fold 4 MAE: 1.61415\n",
      "    Fold 5/5\n",
      "      Fold 5 MAE: 1.64993\n",
      "    -> Average CV MAE for Rg: 1.51071 (+/- 0.11384)\n",
      "\n",
      "✅ Training complete.\n",
      "\n",
      "Submission file 'submission.csv' created successfully.\n",
      "           id          Tg       FFV        Tc   Density         Rg\n",
      "0  1109053969  137.735858  0.367938  0.188724  1.190764  20.052695\n",
      "1  1422188626  158.255820  0.376934  0.228912  1.034065  19.907999\n",
      "2  2032016830   97.877387  0.352247  0.248315  1.122426  21.525931\n"
     ]
    }
   ],
   "source": [
    "# train.py - Corrected and Refactored\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "from rdkit import Chem\n",
    "from mordred import Calculator, descriptors\n",
    "\n",
    "\n",
    "# --- Global Settings ---\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "class CFG:\n",
    "    \"\"\"Configuration class for hyperparameters and settings.\"\"\"\n",
    "    N_SPLITS = 5\n",
    "    SEEDS = [42] # Using more seeds for robustness provides better generalization\n",
    "    TARGET_COLS = ['Tg', 'FFV', 'Tc', 'Density', 'Rg']\n",
    "    \n",
    "    # batch\n",
    "    EPOCHS = 160\n",
    "    BATCH_SIZE = 256\n",
    "    LR = 1e-3\n",
    "    WEIGHT_DECAY = 1e-5\n",
    "    EARLY_STOPPING_PATIENCE = 40\n",
    "    HIDDEN_DIM = 512\n",
    "    N_BLOCKS = 2\n",
    "    DROPOUT_RATE = 0.3\n",
    "    \n",
    "    # Feature Selection\n",
    "    K_BEST_FEATURES = 450\n",
    "    CORR_THRESHOLD = 0.98\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"Sets the seed for reproducibility across all libraries.\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(\"✅ Configuration and seeding function defined.\")\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading data...\")\n",
    "# Assume data is in a standard input directory\n",
    "DATA_DIR = '/kaggle/input/neurips-open-polymer-prediction-2025' # Change this to your data path, e.g., '/kaggle/input/neurips-open-polymer-prediction-2025/'\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\n",
    "sample_submission_df = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'))\n",
    "\n",
    "# --- 2. Feature Engineering Function ---\n",
    "def generate_mordred_descriptors(smiles_series, name):\n",
    "    \"\"\"Calculates and saves Mordred descriptors.\"\"\"\n",
    "    print(f\"Generating Mordred descriptors for {len(smiles_series)} molecules ({name})...\")\n",
    "    \n",
    "    # RDKit molecule conversion\n",
    "    mols = [Chem.MolFromSmiles(s) for s in smiles_series]\n",
    "    \n",
    "    # Initialize Mordred calculator\n",
    "    calc = Calculator(descriptors, ignore_3D=True)\n",
    "    \n",
    "    # Use all available CPU cores for calculation\n",
    "    # The .pandas() method shows the progress bar you are seeing\n",
    "    df_desc = calc.pandas(mols, nproc=os.cpu_count())\n",
    "    \n",
    "    # Post-processing: ensure numeric, fill NaNs, remove constant columns\n",
    "    df_desc = df_desc.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "    df_desc = df_desc.loc[:, df_desc.nunique() > 1] # Important: remove zero-variance features\n",
    "    \n",
    "    print(f\"Generated {df_desc.shape[1]} descriptors for {name}.\")\n",
    "    return df_desc\n",
    "\n",
    "# --- 3. Generate and Save Features ---\n",
    "train_features_df = pd.read_csv(\"/kaggle/input/polymer-dataset-525/train_features.csv\") #generate_mordred_descriptors(train_df['SMILES'], 'train')\n",
    "test_features_df = generate_mordred_descriptors(test_df['SMILES'], 'test')\n",
    "\n",
    "# Align columns after generation - crucial for consistent model input\n",
    "train_cols = set(train_features_df.columns)\n",
    "test_cols = set(test_features_df.columns)\n",
    "shared_cols = sorted(list(train_cols.intersection(test_cols)))\n",
    "\n",
    "train_features_df = train_features_df[shared_cols]\n",
    "test_features_df = test_features_df[shared_cols]\n",
    "\n",
    "\n",
    "train_full_df = pd.concat([train_df, train_features_df], axis=1)\n",
    "test_full_df = pd.concat([test_df, test_features_df], axis=1)\n",
    "\n",
    "print(f\"✅ Features generated. Train shape: {train_full_df.shape}, Test shape: {test_full_df.shape}\")\n",
    "\n",
    "\n",
    "# --- 3. Feature Selection & Target Transformation ---\n",
    "def select_features_in_fold(Xtr_df, ytr, k, corr_th):\n",
    "    \"\"\"Performs supervised feature selection using ONLY fold training data.\"\"\"\n",
    "    if Xtr_df.shape[1] <= k:\n",
    "        return Xtr_df.columns.tolist()\n",
    "\n",
    "    sel_f = SelectKBest(f_regression, k=min(k, Xtr_df.shape[1] - 1)).fit(Xtr_df, ytr)\n",
    "    selected_cols_kbest = Xtr_df.columns[sel_f.get_support()]\n",
    "    Xtr_df_selected = Xtr_df[selected_cols_kbest]\n",
    "\n",
    "    corr = Xtr_df_selected.corr().abs()\n",
    "    f_vals, _ = f_regression(Xtr_df_selected, ytr)\n",
    "    strength = pd.Series(f_vals, index=Xtr_df_selected.columns).fillna(0.0)\n",
    "\n",
    "    ordered_features = strength.sort_values(ascending=False).index\n",
    "    kept_features = []\n",
    "    for feature in ordered_features:\n",
    "        if not kept_features:\n",
    "            kept_features.append(feature)\n",
    "            continue\n",
    "        # Check correlation against already kept features\n",
    "        if not (corr.loc[feature, kept_features] > corr_th).any():\n",
    "            kept_features.append(feature)\n",
    "\n",
    "    return kept_features\n",
    "\n",
    "def get_transforms(y, target):\n",
    "    \"\"\"Applies target transformation for better model training.\"\"\"\n",
    "    if target == \"FFV\":\n",
    "        eps = 1e-4\n",
    "        y_clipped = np.clip(y, eps, 1 - eps)\n",
    "        transform = lambda x: np.log(x / (1 - x)) # Logit transform\n",
    "        inverse = lambda z: 1.0 / (1.0 + np.exp(-z))\n",
    "        return transform(y_clipped), inverse\n",
    "    if target == \"Density\":\n",
    "        transform = lambda x: np.log(np.clip(x, 1e-4, None)) # Log transform\n",
    "        inverse = lambda x: np.exp(x)\n",
    "        return transform(y), inverse\n",
    "    return y, lambda z: z # No transform for other targets\n",
    "\n",
    "print(\"✅ Feature selection and transformation functions defined.\")\n",
    "\n",
    "\n",
    "def run_xgb_pipeline(train_data, test_data, target, random_state):\n",
    "    print(f\"  Target: {target} | Model: XGBoost\")\n",
    "    set_seed(random_state)\n",
    "\n",
    "    train_filtered = train_data[train_data[target].notna()].copy()\n",
    "    y_raw = train_filtered[target].astype(np.float32).values\n",
    "    \n",
    "    # --- CORRECTED: Use shared feature columns ---\n",
    "    feat_cols = shared_cols\n",
    "    X_df = train_filtered[feat_cols]\n",
    "    X_test_df = test_data[feat_cols]\n",
    "\n",
    "    bins = pd.qcut(y_raw, q=10, labels=False, duplicates='drop')\n",
    "    splitter = StratifiedKFold(n_splits=CFG.N_SPLITS, shuffle=True, random_state=random_state)\n",
    "\n",
    "    test_preds = []\n",
    "    fold_maes = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(splitter.split(X_df, bins), 1):\n",
    "        print(f\"    Fold {fold}/{CFG.N_SPLITS}\")\n",
    "        Xtr_df, Xva_df = X_df.iloc[tr_idx], X_df.iloc[va_idx]\n",
    "        ytr_raw, yva_raw = y_raw[tr_idx], y_raw[va_idx]\n",
    "\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        Xtr_df = pd.DataFrame(imputer.fit_transform(Xtr_df), columns=Xtr_df.columns)\n",
    "        Xva_df = pd.DataFrame(imputer.transform(Xva_df), columns=Xva_df.columns)\n",
    "        X_test_fold_df = pd.DataFrame(imputer.transform(X_test_df), columns=X_test_df.columns)\n",
    "        \n",
    "        selected_cols = select_features_in_fold(Xtr_df, ytr_raw, CFG.K_BEST_FEATURES, CFG.CORR_THRESHOLD)\n",
    "        Xtr, Xva, X_test_fold = Xtr_df[selected_cols].values, Xva_df[selected_cols].values, X_test_fold_df[selected_cols].values\n",
    "        \n",
    "        model = xgb.XGBRegressor(\n",
    "            random_state=random_state, objective='reg:absoluteerror', tree_method='hist',\n",
    "            n_estimators=2500, learning_rate=0.015, max_depth=6, subsample=0.8,\n",
    "            colsample_bytree=0.8, reg_alpha=0.1, reg_lambda=1.0, early_stopping_rounds=150\n",
    "        )\n",
    "        model.fit(Xtr, ytr_raw, eval_set=[(Xva, yva_raw)], verbose=False)\n",
    "\n",
    "        val_preds = model.predict(Xva)\n",
    "        fold_test_preds = model.predict(X_test_fold)\n",
    "\n",
    "        ytr_min, ytr_max = np.percentile(ytr_raw, [0.5, 99.5])\n",
    "        test_preds.append(np.clip(fold_test_preds, ytr_min, ytr_max))\n",
    "        \n",
    "        fold_mae = mean_absolute_error(yva_raw, val_preds)\n",
    "        fold_maes.append(fold_mae)\n",
    "        print(f\"      Fold {fold} MAE: {fold_mae:.5f}\")\n",
    "\n",
    "    print(f\"    -> Average CV MAE for {target}: {np.mean(fold_maes):.5f} (+/- {np.std(fold_maes):.5f})\")\n",
    "    return np.mean(test_preds, axis=0)\n",
    "\n",
    "def run_lgbm_pipeline(train_data, test_data, target, random_state):\n",
    "    print(f\"  Target: {target} | Model: LightGBM\")\n",
    "    set_seed(random_state)\n",
    "\n",
    "    train_filtered = train_data[train_data[target].notna()].copy()\n",
    "    y_raw = train_filtered[target].astype(np.float32).values\n",
    "    \n",
    "    # Use all feature columns\n",
    "    feat_cols = [col for col in train_data.columns if col not in ['id', 'SMILES'] + CFG.TARGET_COLS]\n",
    "    X_df = train_filtered[feat_cols]\n",
    "    X_test_df = test_data[feat_cols]\n",
    "\n",
    "    bins = pd.qcut(y_raw, q=10, labels=False, duplicates='drop')\n",
    "    splitter = StratifiedKFold(n_splits=CFG.N_SPLITS, shuffle=True, random_state=random_state)\n",
    "\n",
    "    test_preds = []\n",
    "    fold_maes = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(splitter.split(X_df, bins), 1):\n",
    "        print(f\"    Fold {fold}/{CFG.N_SPLITS}\")\n",
    "        Xtr_df, Xva_df = X_df.iloc[tr_idx], X_df.iloc[va_idx]\n",
    "        ytr_raw, yva_raw = y_raw[tr_idx], y_raw[va_idx]\n",
    "\n",
    "        imputer = SimpleImputer(strategy='median')\n",
    "        Xtr = imputer.fit_transform(Xtr_df)\n",
    "        Xva = imputer.transform(Xva_df)\n",
    "        X_test_fold = imputer.transform(X_test_df)\n",
    "\n",
    "        model = lgb.LGBMRegressor(\n",
    "            random_state=random_state,\n",
    "            objective='mae',\n",
    "            metric='mae',\n",
    "            n_estimators=2000,\n",
    "            learning_rate=0.01,\n",
    "            num_leaves=31,\n",
    "            max_depth=-1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.1,\n",
    "            reg_lambda=0.1,\n",
    "            n_jobs=-1,\n",
    "            verbose=-1\n",
    "        )\n",
    "        \n",
    "        model.fit(Xtr, ytr_raw,\n",
    "                  eval_set=[(Xva, yva_raw)],\n",
    "                  callbacks=[lgb.early_stopping(100, verbose=False)])\n",
    "\n",
    "        val_preds = model.predict(Xva)\n",
    "        fold_test_preds = model.predict(X_test_fold)\n",
    "\n",
    "        ytr_min, ytr_max = np.percentile(ytr_raw, [0.5, 99.5])\n",
    "        test_preds.append(np.clip(fold_test_preds, ytr_min, ytr_max))\n",
    "        \n",
    "        fold_mae = mean_absolute_error(yva_raw, val_preds)\n",
    "        fold_maes.append(fold_mae)\n",
    "        print(f\"      Fold {fold} MAE: {fold_mae:.5f}\")\n",
    "\n",
    "    print(f\"    -> Average CV MAE for {target}: {np.mean(fold_maes):.5f} (+/- {np.std(fold_maes):.5f})\")\n",
    "    return np.mean(test_preds, axis=0)\n",
    "\n",
    "\n",
    "# --- 5. Main Execution ---\n",
    "final_preds = {}\n",
    "ID_test = test_df['id']\n",
    "\n",
    "# --- DEFINE WHICH MODEL TO RUN FOR EACH TARGET ---\n",
    "# You can change this to run different models, e.g., 'lgbm', 'catboost', 'xgb'\n",
    "# This allows for easy experimentation. Let's run CatBoost for all to start.\n",
    "MODEL_CHOICE = {\n",
    "    'Tg': 'lgbm',\n",
    "    'FFV': 'lgbm',\n",
    "    'Tc': 'lgbm',\n",
    "    'Density': 'lgbm',\n",
    "    'Rg': 'lgbm',\n",
    "}\n",
    "\n",
    "# --- MODEL MAPPING ---\n",
    "# This maps the string choice to the actual function to run\n",
    "MODEL_FUNCTIONS = {\n",
    "    'xgb': run_xgb_pipeline,\n",
    "    'lgbm': run_lgbm_pipeline,\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\n=== Initiating Training ===\")\n",
    "for target in CFG.TARGET_COLS:\n",
    "    print(f\"\\n[{target.upper()}]\")\n",
    "    \n",
    "    model_name = MODEL_CHOICE[target] \n",
    "    model_func = MODEL_FUNCTIONS[model_name]\n",
    "    \n",
    "    seed_preds = []\n",
    "    for seed in CFG.SEEDS:\n",
    "        print(f\"\\n--- Training with seed: {seed} ---\")\n",
    "        preds = model_func(train_full_df, test_full_df, target, random_state=seed)\n",
    "        seed_preds.append(preds)\n",
    "        gc.collect()\n",
    "\n",
    "    # Average predictions across different seeds\n",
    "    final_preds[target] = np.mean(seed_preds, axis=0)\n",
    "\n",
    "print(\"\\n✅ Training complete.\")\n",
    "\n",
    "# --- 6. Create Submission File ---\n",
    "submission_df = pd.DataFrame({'id': ID_test})\n",
    "for target in CFG.TARGET_COLS:\n",
    "    # This ensures the correct predictions are assigned to the correct column\n",
    "    submission_df[target] = final_preds[target]\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"\\nSubmission file 'submission.csv' created successfully.\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12966160,
     "sourceId": 74608,
     "sourceType": "competition"
    },
    {
     "datasetId": 7678100,
     "sourceId": 12189904,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7706066,
     "sourceId": 12237259,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7887657,
     "sourceId": 12501403,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8256291,
     "sourceId": 13038718,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 502.913362,
   "end_time": "2025-09-12T16:21:31.237818",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-12T16:13:08.324456",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
